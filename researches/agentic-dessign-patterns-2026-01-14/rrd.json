{
  "project": "Research: Agentic Design Patterns",
  "branchName": "research/agentic-design-patterns",
  "description": "Scout recent advances in design patterns for AI agents and multi-agent systems. Focus on architectural patterns for building reliable, composable, and scalable autonomous agents. Looking for patterns around agent orchestration, tool use, memory management, planning, reflection, and multi-agent collaboration that can be practically implemented.",
  "requirements": {
    "focus_area": "AI agents",
    "keywords": [
      "agentic AI patterns",
      "LLM agent architecture",
      "multi-agent systems",
      "agent orchestration",
      "ReAct prompting",
      "chain-of-thought agents",
      "tool-use agents",
      "agent memory systems"
    ],
    "time_window_days": 90,
    "historical_lookback_days": 1095,
    "target_papers": 30,
    "sources": [
      "arXiv",
      "Google Scholar",
      "web"
    ],
    "min_score_to_present": 18
  },
  "domain_glossary": {
    "enabled": true,
    "terms": {
      "ReAct": "Reasoning and Acting - pattern combining reasoning traces with action execution",
      "CoT": "Chain-of-Thought - prompting technique for step-by-step reasoning",
      "RAG": "Retrieval-Augmented Generation",
      "MAS": "Multi-Agent System",
      "ToT": "Tree-of-Thoughts - exploration of multiple reasoning paths",
      "MCTS": "Monte Carlo Tree Search - used in agent planning",
      "Reflection": "Agent self-critique and iterative improvement pattern"
    }
  },
  "open_questions": [],
  "phase": "ANALYSIS",
  "papers_pool": [
    {
      "id": "arxiv_2601.03624",
      "title": "Architecting Agentic Communities using Design Patterns",
      "url": "https://arxiv.org/abs/2601.03624",
      "pdf_url": "https://arxiv.org/pdf/2601.03624",
      "authors": [
        "Zoran Milosevic",
        "Fethi Rabhi"
      ],
      "date": "2026-01-07",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 23,
      "score_breakdown": {
        "novelty": 4,
        "feasibility": 4,
        "time_to_poc": 3,
        "value_market": 5,
        "defensibility": 3,
        "adoption": 4
      },
      "analysis": {
        "summary": "Comprehensive design pattern catalogue (46 patterns) for agentic AI systems organized in three tiers: LLM Agents (task automation), Agentic AI (autonomous reasoning), and Agentic Communities (multi-participant coordination). Uniquely grounds patterns in ISO ODP-EL formal semantics enabling verifiable governance.",
        "methodology": "Three-tier classification derived from enterprise distributed systems standards (ISO/IEC 15414). Uses deontic tokens (burden/permit/embargo) for formal accountability. Three-step design methodology: assess use case, apply pattern composition, scope implementation.",
        "results": "46 patterns catalogued (11 LLM Agent, 22 Agentic AI, 13 Agentic Community). Clinical trial matching case study validates approach. Formal verification properties for safety, authority, prohibition, and accountability.",
        "implementations_found": [
          "https://github.com/sarwarbeing-ai/Agentic_Design_Patterns",
          "https://github.com/promptadvisers/agentic-design-patterns-docs",
          "https://github.com/nibzard/awesome-agentic-patterns",
          "https://github.com/ksm26/AI-Agentic-Design-Patterns-with-AutoGen"
        ],
        "commercialized": false,
        "limitations": "Initial pattern set; domain-specific instantiations needed for finance/manufacturing/cybersecurity. Formal verification focus on governance patterns only. Learning curve for ODP-EL framework."
      },
      "decision": "PRESENT",
      "notes": "Highest-value paper for research focus. Three-tier framework directly applicable to building production agents. ODP-EL formal grounding distinguishes from narrative pattern catalogues. Cross-references: ReAct, Reflexion, Constitutional AI, Plan-then-Execute patterns appear in other papers."
    },
    {
      "id": "arxiv_2601.03328",
      "title": "LLM-Enabled Multi-Agent Systems: Empirical Evaluation and Insights into Emerging Design Patterns & Paradigms",
      "url": "https://arxiv.org/abs/2601.03328",
      "pdf_url": "https://arxiv.org/pdf/2601.03328",
      "authors": [
        "Harri Renney",
        "Maxim N Nethercott",
        "Nathan Renney",
        "Peter Hayes"
      ],
      "date": "2026-01-06",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 23,
      "score_breakdown": {
        "novelty": 3,
        "feasibility": 5,
        "time_to_poc": 5,
        "value_market": 4,
        "defensibility": 2,
        "adoption": 4
      },
      "analysis": {
        "summary": "Empirical evaluation of LLM-enabled multi-agent systems across three real-world domains: telecom security, heritage asset management, and utilities customer service. Formalizes design patterns including ReAct agents, Single Information Environment (SIE), hierarchical architectures, supervisor patterns, and swarm configurations.",
        "methodology": "Three controlled containerized pilots with stakeholder feedback, sentiment analysis, UAT with Likert scales (correctness, usefulness, clarity, groundedness, safety). Measures development velocity, cost efficiency, and throughput.",
        "results": "Prototypes delivered in 2 weeks, pilot-ready in 1 month. CS3 achieved 100% email categorization accuracy, 4.3/5 quality rating, 5 emails/min throughput vs 3 baseline, ~£0.05/email vs £0.33 for regex. Critical gap identified between rapid prototyping and production maturity due to LLM behavioral variability.",
        "implementations_found": [
          "https://github.com/NisaarAgharia/AI-Agents",
          "https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/"
        ],
        "commercialized": true,
        "commercialized_by": "Kaze Technologies/Kaze Consulting (authors' company, Bath, UK)",
        "limitations": "Variability in LLM outputs, hallucination risks, lack of robust guardrails for regulated domains. Human oversight remains persistent requirement. Coordination overhead scales with agent network size."
      },
      "decision": "PRESENT",
      "notes": "Highly practical paper with real empirical data. Key insight: prototype speed doesn't translate to production speed. Patterns validated across 3 enterprise domains. Cross-references SIE architecture, hierarchical patterns from arxiv_2601.03624."
    },
    {
      "id": "arxiv_2508.10146",
      "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges",
      "url": "https://arxiv.org/abs/2508.10146",
      "pdf_url": "https://arxiv.org/pdf/2508.10146",
      "authors": [
        "Hana Derouiche",
        "Zaki Brahmi",
        "Haithem Mazeni"
      ],
      "date": "2025-08-13",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 23,
      "score_breakdown": {
        "novelty": 3,
        "feasibility": 5,
        "time_to_poc": 5,
        "value_market": 4,
        "defensibility": 2,
        "adoption": 4
      },
      "analysis": {
        "summary": "Systematic review and comparative analysis of 7 major agentic AI frameworks (CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, MetaGPT) and 4 agent communication protocols (MCP, ACP, A2A, ANP). Establishes foundational taxonomy for agentic AI systems covering orchestration, memory, guardrails, and service computing readiness.",
        "methodology": "Multi-dimensional framework comparison across: architectural approaches (graph-based vs role-based vs conversational), memory implementations (stateful nodes vs agent-level vs shared dialogue), guardrails (validators, retry logic, trust layers), and SOA alignment. Protocol analysis covers message formats, discovery mechanisms, and transport layers.",
        "results": "Framework categorization: Orchestration-focused (AutoGen, CrewAI, MetaGPT), Graph-based enterprise (LangGraph, Semantic Kernel, Google ADK), Lightweight declarative (Agno, SmolAgents). Identifies 5 critical design challenges: rigid architectures, no runtime discovery, code safety risks, interoperability gaps, missing standards. Proposes 5 strategic recommendations for interoperability.",
        "implementations_found": [
          "https://github.com/a2aproject/A2A",
          "https://github.com/agent-network-protocol/AgentNetworkProtocol",
          "https://github.com/langchain-ai/langgraph",
          "https://github.com/crewAIInc/crewAI",
          "https://github.com/microsoft/autogen"
        ],
        "commercialized": true,
        "commercialized_by": "All frameworks analyzed are production-ready: LangChain/LangGraph (LangChain Inc), CrewAI (CrewAI Inc), AutoGen (Microsoft), Semantic Kernel (Microsoft), Google ADK (Google)",
        "limitations": "Survey paper - no novel technique proposed. Protocol landscape rapidly evolving (A2A launched June 2025 under Linux Foundation). Service computing integration remains nascent across all frameworks. Benchmarks for objective comparison still lacking."
      },
      "decision": "PRESENT",
      "notes": "Essential reference for framework selection. Five design challenges directly inform production architecture decisions. Protocol comparison (A2A vs ANP) clarifies interoperability strategy. Cross-references: memory patterns relate to arxiv_2601.08816 (MemRec), guardrails patterns to arxiv_2506.08837 (security patterns)."
    },
    {
      "id": "arxiv_2510.09244",
      "title": "Fundamentals of Building Autonomous LLM Agents",
      "url": "https://arxiv.org/abs/2510.09244",
      "pdf_url": "https://arxiv.org/pdf/2510.09244",
      "authors": [
        "Victor de Lamo Castrillo",
        "Habtom Kahsay Gidey",
        "Alexander Lenz",
        "Alois Knoll"
      ],
      "date": "2025-10-10",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 19,
      "score_breakdown": {
        "novelty": 2,
        "feasibility": 5,
        "time_to_poc": 4,
        "value_market": 3,
        "defensibility": 1,
        "adoption": 4
      },
      "analysis": {
        "summary": "TUM seminar technical report defining a four-component architecture for autonomous LLM agents: Perception (environmental sensing), Reasoning (planning and adaptation), Memory (short/long-term storage), and Execution (action translation). Synthesizes existing patterns (ReAct, CoT, ToT, RAG, MCTS) into a coherent educational framework with practical design recommendations.",
        "methodology": "Structured review organizing agent capabilities into four cognitive-inspired systems. Identifies four perception approaches (text, multimodal, structured data, tool-augmented), four reasoning patterns (task decomposition, multi-plan generation, reflection, multi-agent experts), three memory types (long-term RAG/SQL, short-term context, storage types), and four execution modes (tool, visual, code, robotic).",
        "results": "Highlights critical performance gap: humans achieve 72%+ task completion on OSWorld benchmarks vs 43% for leading AI. Identifies four key challenges: GUI grounding unreliability, repetitive action loops, UI robustness failures, context window limitations. Provides 5 practical recommendations for agent builders.",
        "implementations_found": [
          "https://github.com/artnitolog/awesome-agent-learning",
          "https://github.com/HKUDS/AutoAgent",
          "https://github.com/victordibia/designing-multiagent-systems",
          "https://github.com/tmgthb/Autonomous-Agents"
        ],
        "commercialized": false,
        "limitations": "Educational synthesis - no novel techniques. Does not advance state-of-art. Benchmark gaps highlight remaining challenges but offers no solutions. Context window constraints acknowledged but not addressed."
      },
      "decision": "PRESENT",
      "notes": "Foundational reference for understanding agent architecture components. Four-component framework provides clear mental model for agent design. Benchmark gap analysis (72% human vs 43% AI) quantifies current limitations. Cross-references ReAct, CoT, ToT, RAG patterns covered in other papers."
    },
    {
      "id": "arxiv_2509.08646",
      "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations",
      "url": "https://arxiv.org/abs/2509.08646",
      "pdf_url": "https://arxiv.org/pdf/2509.08646",
      "authors": [
        "Ron F. Del Rosario",
        "Klaudia Krawiecka",
        "Christian Schroeder de Witt"
      ],
      "date": "2025-09-10",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 25,
      "score_breakdown": {
        "novelty": 4,
        "feasibility": 5,
        "time_to_poc": 4,
        "value_market": 5,
        "defensibility": 3,
        "adoption": 4
      },
      "analysis": {
        "summary": "Comprehensive security-first guide to Plan-then-Execute (P-t-E) architecture for LLM agents. Separates strategic planning from tactical execution, with Planner generating structured plans (JSON, DAG, or natural language) before Executor carries out steps. Core innovation is framing P-t-E as an inherent defense against indirect prompt injection via control-flow integrity.",
        "methodology": "Defense-in-depth strategy incorporating: (1) Control-flow integrity - plans generated in trusted state before ingesting untrusted data, (2) Principle of least privilege - executors receive only task-scoped tools, (3) Dual LLM pattern - separate privileged and quarantined LLMs, (4) Input sanitization and output filtering, (5) Docker containerization for code execution, (6) Human-in-the-loop verification for critical actions.",
        "results": "Provides implementation blueprints for three frameworks: LangGraph (state machines with conditional edges for re-planning), CrewAI (hierarchical processes with declarative tool scoping), AutoGen (GroupChat with native Docker support). Under review at SAP as recommended architecture pattern for multi-agent agentic solutions.",
        "implementations_found": [
          "https://github.com/RichardHGL/CHI2025_Plan-then-Execute_LLMAgent",
          "https://github.com/dasiths/llm-plan-and-execute-knowledge-provider-mesh",
          "https://github.com/gitcommitshow/resilient-llm"
        ],
        "commercialized": true,
        "commercialized_by": "SAP (under review for adoption as recommended architecture); framework implementations in LangChain, CrewAI, AutoGen",
        "limitations": "Upfront latency from planning phase. High token consumption during plan generation. Wasted effort if early steps fail without re-planning capability. Not a substitute for general AI security practices - still requires data protection, pipeline security, RAG access controls."
      },
      "decision": "PRESENT",
      "notes": "Highest-scoring paper so far (25/30). Security-first framing of P-t-E is critical for production systems. SAP enterprise adoption validates market need. Cross-references: complements arxiv_2506.08837 (security patterns), extends Plan-then-Execute pattern from arxiv_2601.03624 three-tier framework. Related CHI2025 human study shows users struggle calibrating trust in P-t-E outputs."
    },
    {
      "id": "arxiv_2506.08837",
      "title": "Design Patterns for Securing LLM Agents against Prompt Injections",
      "url": "https://arxiv.org/abs/2506.08837",
      "pdf_url": "https://arxiv.org/pdf/2506.08837",
      "authors": [
        "Luca Beurer-Kellner",
        "Beat Buesser",
        "Ana-Maria Cretu",
        "Edoardo Debenedetti",
        "Daniel Dobos",
        "Daniel Fabian",
        "Marc Fischer",
        "David Froelicher",
        "Kathrin Grosse",
        "Daniel Naeff",
        "Ezinwanne Ozoani",
        "Andrew Paverd",
        "Florian Tramèr",
        "Václav Volhejn"
      ],
      "date": "2025-06-10",
      "source": "arXiv",
      "priority": 4,
      "status": "presented",
      "score": 26,
      "score_breakdown": {
        "novelty": 5,
        "feasibility": 4,
        "time_to_poc": 4,
        "value_market": 5,
        "defensibility": 4,
        "adoption": 4
      },
      "analysis": {
        "summary": "Comprehensive security framework proposing six principled design patterns for building AI agents with provable resistance to prompt injection: Action-Selector, Plan-Then-Execute, LLM Map-Reduce, Dual LLM, Code-Then-Execute, and Context-Minimization. Each pattern provides architectural guarantees against specific threat vectors by constraining agent capabilities in controlled ways.",
        "methodology": "Threat modeling for 10 application scenarios (OS Assistant, SQL Agent, Email/Calendar, Customer Service, Booking, Product Recommender, Resume Screening, Medication Chatbot, Medical Diagnosis, Software Engineering). Each pattern analyzed for: attacker capabilities, trust boundaries, harm vectors, and security-utility trade-offs.",
        "results": "Six patterns formalized with provable security properties. Action-Selector provides immunity via no feedback loops. Plan-Then-Execute implements control-flow integrity. Map-Reduce prevents cross-document manipulation. Dual LLM achieves privilege separation. Code-Then-Execute makes manipulation visible through formal syntax. Context-Minimization removes injection surface after initial processing.",
        "implementations_found": [
          "https://pondevelopment.github.io/llm-prompt-injection-mitigation-patterns/",
          "https://github.com/tldrsec/prompt-injection-defenses",
          "https://github.com/Joe-B-Security/awesome-prompt-injection",
          "https://www.archestra.ai/blog/dual-llm"
        ],
        "commercialized": true,
        "commercialized_by": "Authors from IBM, Invariant Labs, ETH Zurich, Google, Microsoft. Archestra AI offers commercial Dual LLM implementation. Multiple guardrail products (LLM Guard, NeMo-Guardrails, IBM Granite Guardian) implement related patterns.",
        "limitations": "Patterns designed for application-specific rather than general-purpose agents. Quarantined LLMs remain vulnerable to manipulation (no tools mitigates but doesn't eliminate). User confirmation suffers from alert fatigue. Data attribution imperfect. Applicability depends on task decomposability."
      },
      "decision": "PRESENT",
      "notes": "Highest-scoring paper (26/30). Multi-institution collaboration (IBM, Google, Microsoft, ETH Zurich) validates rigor. Key assertion: general-purpose agents cannot provide meaningful security guarantees - application-specific patterns with constrained capabilities are the path forward. Directly complements arxiv_2509.08646 (P-t-E security focus). Six patterns form authoritative reference for production agent security."
    },
    {
      "id": "arxiv_2505.07087",
      "title": "Applying Cognitive Design Patterns to General LLM Agents",
      "url": "https://arxiv.org/abs/2505.07087",
      "pdf_url": "https://arxiv.org/pdf/2505.07087",
      "authors": [
        "Robert E. Wray",
        "James R. Kirk",
        "John E. Laird"
      ],
      "date": "2025-05-11",
      "source": "arXiv",
      "priority": 5,
      "status": "presented",
      "score": 18,
      "score_breakdown": {
        "novelty": 4,
        "feasibility": 3,
        "time_to_poc": 3,
        "value_market": 3,
        "defensibility": 2,
        "adoption": 3
      },
      "analysis": {
        "summary": "Maps cognitive design patterns from pre-transformer AI architectures (Soar, ACT-R, BDI) to modern LLM-based agents. Identifies six key patterns: Observe-Decide-Act (present in ReAct but lacking explicit commitment), Hierarchical Decomposition (Voyager, ToT), Memory Types (episodic, semantic, procedural), Knowledge Compilation (ExpeL, Reflexion), Commitment & Reconsideration (underexplored gap), and Step-wise Reflection (novel LLM-specific pattern).",
        "methodology": "Comparative cognitive architecture analysis examining how patterns from 40+ years of cognitive science research manifest in agentic LLM systems. Addresses three research questions: which patterns appear in existing systems, which remain underexplored, and whether LLMs suggest novel patterns. Framework-agnostic analysis applicable across agent implementations.",
        "results": "Identifies commitment and reconsideration as critical underexplored pattern in LLM agents - ReAct implements observe-decide-act but lacks explicit commitment stage that enables reconsidering prior choices. Knowledge compilation (caching reasoning into reusable forms) identified as strategically important given computational costs of reasoning models. Step-wise reflection identified as novel LLM-specific pattern.",
        "implementations_found": [
          "https://github.com/SoarGroup/Soar",
          "https://github.com/soartech/jsoar",
          "https://github.com/ysymyth/awesome-language-agents"
        ],
        "commercialized": false,
        "commercialized_by": "Soar Technology Inc (defense-focused AI; no direct LLM product)",
        "limitations": "Theoretical framework without direct implementation. Requires cognitive architecture expertise to apply. Research-oriented with limited immediate commercial application. Patterns are public knowledge synthesis from existing literature."
      },
      "decision": "PRESENT",
      "notes": "AGI25 oral presentation (Springer LNCS vol 16058). Bridges cognitive science theory and LLM agents. Key gap identified: commitment/reconsideration pattern missing from ReAct. Authors from Soar Technology Inc / Center for Integrated Cognition with 40+ years of cognitive architecture research. Cross-references: CoALA framework, BDI architectures, relates to memory patterns in arxiv_2508.10146 and four-component model in arxiv_2510.09244."
    },
    {
      "id": "arxiv_2404.11584",
      "title": "The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey",
      "url": "https://arxiv.org/abs/2404.11584",
      "pdf_url": "https://arxiv.org/pdf/2404.11584",
      "authors": [
        "Tula Masterman",
        "Sandi Besen",
        "Mason Sawtell",
        "Alex Chao"
      ],
      "date": "2024-04-17",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Comprehensive survey of single and multi-agent architectures. Leadership, communication, planning-execution-evaluation patterns."
    },
    {
      "id": "arxiv_2511.03023",
      "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework",
      "url": "https://arxiv.org/abs/2511.03023",
      "pdf_url": "https://arxiv.org/pdf/2511.03023",
      "authors": [
        "Sina Montazeri",
        "Yunhe Feng",
        "Kewei Sha"
      ],
      "date": "2025-11-04",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Five core design principles from empirical evaluation. Agent specialization, universal vs conditional agents, failure mode analysis."
    },
    {
      "id": "arxiv_2512.20845",
      "title": "MAR: Multi-Agent Reflexion Improves Reasoning Abilities in LLMs",
      "url": "https://arxiv.org/abs/2512.20845",
      "pdf_url": "https://arxiv.org/pdf/2512.20845",
      "authors": [
        "Onat Ozer",
        "Grace Wu",
        "Yuchen Wang",
        "Daniel Dosti",
        "Honghao Zhang",
        "Vivi De La Rue"
      ],
      "date": "2025-12-23",
      "source": "arXiv",
      "priority": 5,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Multi-agent reflexion pattern. Addresses degeneration of thought in single-agent reflection. Multi-persona debate for diverse reflections."
    },
    {
      "id": "arxiv_2503.16024",
      "title": "The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement",
      "url": "https://arxiv.org/abs/2503.16024",
      "pdf_url": "https://arxiv.org/pdf/2503.16024",
      "authors": [
        "Ruihan Yang",
        "Fanghua Ye",
        "Jian Li",
        "Siyu Yuan",
        "Yikai Zhang",
        "Zhaopeng Tu",
        "Xiaolong Li",
        "Deqing Yang"
      ],
      "date": "2025-03-20",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "NeurIPS 2025. Critic-guided improvement pattern. Small critic model surpasses GPT-4 in feedback quality."
    },
    {
      "id": "arxiv_2511.02303",
      "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation",
      "url": "https://arxiv.org/abs/2511.02303",
      "pdf_url": "https://arxiv.org/pdf/2511.02303",
      "authors": [
        "Zhiwei Zhang",
        "Xiaomin Li",
        "Yudi Lin",
        "Hui Liu",
        "et al."
      ],
      "date": "2025-11-04",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Addresses lazy agent problem in multi-agent reasoning. Causal influence measurement and verifiable rewards."
    },
    {
      "id": "arxiv_2505.00875",
      "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines",
      "url": "https://arxiv.org/abs/2505.00875",
      "pdf_url": "https://arxiv.org/pdf/2505.00875",
      "authors": [
        "Ramesh Manuvinakurike",
        "Emanuel Moss",
        "Elizabeth Anne Watkins",
        "Saurav Sahay",
        "Giuseppe Raffa",
        "Lama Nachman"
      ],
      "date": "2025-05-01",
      "source": "arXiv",
      "priority": 3,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "CHI 2025 Workshop. Critical view: CoT alone doesn't improve outputs or explainability in agentic pipelines."
    },
    {
      "id": "arxiv_2512.14474",
      "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
      "url": "https://arxiv.org/abs/2512.14474",
      "pdf_url": "https://arxiv.org/pdf/2512.14474",
      "authors": [
        "Annu Rana",
        "Gaurav Kumar"
      ],
      "date": "2025-12-16",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Model-First Reasoning pattern. Explicit problem modeling before planning. Outperforms CoT and ReAct on complex planning."
    },
    {
      "id": "arxiv_2502.05078",
      "title": "Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures",
      "url": "https://arxiv.org/abs/2502.05078",
      "pdf_url": "https://arxiv.org/pdf/2502.05078",
      "authors": [
        "Tushar Pandey",
        "Ara Ghukasyan",
        "Oktay Goktas",
        "Santosh Kumar Radha"
      ],
      "date": "2025-02-07",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Unifies CoT, ToT, GoT. Dynamic DAG reasoning. 46.2% improvement on GPQA without training."
    },
    {
      "id": "arxiv_2401.14295",
      "title": "Demystifying Chains, Trees, and Graphs of Thoughts",
      "url": "https://arxiv.org/abs/2401.14295",
      "pdf_url": "https://arxiv.org/pdf/2401.14295",
      "authors": [
        "Maciej Besta",
        "Florim Memedi",
        "Zhenyu Zhang",
        "et al."
      ],
      "date": "2024-01-25",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "IEEE TPAMI 2025. Comprehensive taxonomy of reasoning topologies. Foundation for understanding structured prompting patterns."
    },
    {
      "id": "arxiv_2601.08816",
      "title": "MemRec: Collaborative Memory-Augmented Agentic Recommender System",
      "url": "https://arxiv.org/abs/2601.08816",
      "pdf_url": "https://arxiv.org/pdf/2601.08816",
      "authors": [
        "Weixin Chen",
        "Yuhan Zhao",
        "Jingyuan Huang",
        "et al."
      ],
      "date": "2026-01-13",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Decouples reasoning from memory management. Dedicated memory management LLM pattern. Async background processing."
    },
    {
      "id": "arxiv_2601.08815",
      "title": "Agent Contracts: A Formal Framework for Resource-Bounded Autonomous AI Systems",
      "url": "https://arxiv.org/abs/2601.08815",
      "pdf_url": "https://arxiv.org/pdf/2601.08815",
      "authors": [
        "Qing Ye",
        "Jing Tan"
      ],
      "date": "2026-01-13",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Contract-based governance for resource-bounded agents. Conservation laws for hierarchical delegation. Token reduction patterns."
    },
    {
      "id": "arxiv_2601.08747",
      "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
      "url": "https://arxiv.org/abs/2601.08747",
      "pdf_url": "https://arxiv.org/pdf/2601.08747",
      "authors": [
        "Rubing Chen",
        "Jian Wang",
        "Wenjie Li",
        "Xiao-Yong Wei",
        "Qing Li"
      ],
      "date": "2026-01-13",
      "source": "arXiv",
      "priority": 4,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "ACE framework - metacognition-inspired. Orchestrator decides between retriever and reasoner agents dynamically."
    },
    {
      "id": "arxiv_2601.08699",
      "title": "RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis",
      "url": "https://arxiv.org/abs/2601.08699",
      "pdf_url": "https://arxiv.org/pdf/2601.08699",
      "authors": [
        "Zhengwei Tao",
        "Bo Li",
        "Jialong Wu",
        "Guochen Yan",
        "et al."
      ],
      "date": "2026-01-13",
      "source": "arXiv",
      "priority": 3,
      "status": "pending",
      "score": null,
      "score_breakdown": null,
      "analysis": null,
      "decision": null,
      "notes": "Agentic RAG skill training via data synthesis. Adversarial distractor navigation pattern."
    }
  ],
  "insights": [
    {
      "id": "insight_001",
      "paper_id": "arxiv_2601.03624",
      "insight": "Three-tier agent classification (LLM Agents→Agentic AI→Agentic Communities) provides clear scoping for incremental system development",
      "tags": ["architecture", "taxonomy", "incremental-development"],
      "cross_refs": []
    },
    {
      "id": "insight_002",
      "paper_id": "arxiv_2601.03624",
      "insight": "Deontic tokens (burden/permit/embargo) enable formal accountability chains in multi-agent systems - critical for regulated industries",
      "tags": ["governance", "compliance", "formal-methods"],
      "cross_refs": []
    },
    {
      "id": "insight_003",
      "paper_id": "arxiv_2601.03624",
      "insight": "Pattern composition strategies: Vertical (foundational→sophisticated), Horizontal (peer patterns), Cross-Cutting (governance overlay)",
      "tags": ["composition", "architecture", "patterns"],
      "cross_refs": []
    },
    {
      "id": "insight_004",
      "paper_id": "arxiv_2601.03624",
      "insight": "Intent vs Obligation distinction: Internal intent (non-transferable) vs External obligation (delegable with traceability) preserves agent autonomy while enabling responsibility chains",
      "tags": ["governance", "delegation", "accountability"],
      "cross_refs": []
    },
    {
      "id": "insight_005",
      "paper_id": "arxiv_2601.03328",
      "insight": "Prototype-to-production gap: MAS prototypes can be delivered in 2 weeks, but production maturity requires extensive tuning for LLM variability - plan for 3-6x longer stabilization phase",
      "tags": ["development-velocity", "production", "planning"],
      "cross_refs": ["arxiv_2601.03624"]
    },
    {
      "id": "insight_006",
      "paper_id": "arxiv_2601.03328",
      "insight": "Single Information Environment (SIE) pattern: Data-centric design where specialist agents handle unique datasets with coordinators routing queries - effective for knowledge-intensive domains",
      "tags": ["architecture", "patterns", "data-centric"],
      "cross_refs": []
    },
    {
      "id": "insight_007",
      "paper_id": "arxiv_2601.03328",
      "insight": "Human oversight is a persistent requirement across all tested domains - MAS should augment not replace human decision-making, especially in high-stakes/regulated environments",
      "tags": ["governance", "human-in-loop", "production"],
      "cross_refs": ["arxiv_2601.03624"]
    },
    {
      "id": "insight_008",
      "paper_id": "arxiv_2601.03328",
      "insight": "Cost efficiency pattern: LLM-based specialist agents can achieve 6x cost reduction (£0.05 vs £0.33/email) and 66% throughput improvement over regex baselines when properly architected",
      "tags": ["cost", "efficiency", "benchmarks"],
      "cross_refs": []
    },
    {
      "id": "insight_009",
      "paper_id": "arxiv_2508.10146",
      "insight": "Framework selection heuristic: Graph-based (LangGraph) for complex branching workflows; Role-based (CrewAI) for team-oriented collaboration; Conversational (AutoGen) for rapid prototyping and human-in-loop scenarios",
      "tags": ["framework-selection", "architecture", "decision-guidance"],
      "cross_refs": ["arxiv_2601.03328"]
    },
    {
      "id": "insight_010",
      "paper_id": "arxiv_2508.10146",
      "insight": "Five critical design challenges in current frameworks: (1) Rigid architectures limit mid-execution adaptation, (2) No runtime peer discovery, (3) Code safety risks in generated code, (4) Framework-specific abstractions block interop, (5) Missing universal communication standards",
      "tags": ["challenges", "limitations", "production"],
      "cross_refs": ["arxiv_2601.03624"]
    },
    {
      "id": "insight_011",
      "paper_id": "arxiv_2508.10146",
      "insight": "A2A vs ANP protocol positioning: A2A (Google/Linux Foundation) for enterprise peer-to-peer task orchestration via Agent Cards; ANP for decentralized discovery using DIDs and semantic JSON-LD - complementary not competing",
      "tags": ["protocols", "interoperability", "standards"],
      "cross_refs": []
    },
    {
      "id": "insight_012",
      "paper_id": "arxiv_2508.10146",
      "insight": "Memory implementation patterns vary by framework: LangGraph uses stateful graph nodes; CrewAI provides agent-level memory (ChromaDB short-term, SQLite long-term); AutoGen maintains shared dialogue context; Semantic Kernel offers modular semantic/procedural/episodic variants",
      "tags": ["memory", "architecture", "patterns"],
      "cross_refs": ["arxiv_2601.08816"]
    },
    {
      "id": "insight_013",
      "paper_id": "arxiv_2510.09244",
      "insight": "Four-component agent architecture: Perception (environmental sensing), Reasoning (planning/adaptation), Memory (short/long-term storage), Execution (action translation) - provides foundational mental model for agent design",
      "tags": ["architecture", "fundamentals", "cognitive-patterns"],
      "cross_refs": ["arxiv_2601.03624", "arxiv_2508.10146"]
    },
    {
      "id": "insight_014",
      "paper_id": "arxiv_2510.09244",
      "insight": "Human-AI performance gap quantified: 72%+ task completion for humans vs ~43% for leading AI on OSWorld benchmarks - sets realistic expectations for agent capabilities",
      "tags": ["benchmarks", "limitations", "expectations"],
      "cross_refs": []
    },
    {
      "id": "insight_015",
      "paper_id": "arxiv_2510.09244",
      "insight": "Agent vs workflow distinction: 'Simply augmenting an LLM with modules, tools, or predefined steps does not make it an agent' - agents act according to feedback rather than following fixed workflows",
      "tags": ["definitions", "fundamentals", "autonomy"],
      "cross_refs": ["arxiv_2601.03624"]
    },
    {
      "id": "insight_016",
      "paper_id": "arxiv_2509.08646",
      "insight": "Control-flow integrity for prompt injection defense: Generate plans in trusted state BEFORE ingesting untrusted external data via tools - once established, plan sequence cannot be altered by malicious tool outputs",
      "tags": ["security", "prompt-injection", "control-flow"],
      "cross_refs": ["arxiv_2506.08837"]
    },
    {
      "id": "insight_017",
      "paper_id": "arxiv_2509.08646",
      "insight": "Principle of least privilege for agents: Executors receive only task-scoped tools for immediate step - frameworks like CrewAI enable dynamic tool provisioning, preventing unauthorized function calls even under prompt injection",
      "tags": ["security", "least-privilege", "tool-access"],
      "cross_refs": ["arxiv_2508.10146"]
    },
    {
      "id": "insight_018",
      "paper_id": "arxiv_2509.08646",
      "insight": "Dual LLM pattern: Separate 'privileged' LLM for planning/sensitive operations from 'quarantined' LLM that processes untrusted inputs - architectural isolation prevents privilege escalation",
      "tags": ["security", "architecture", "isolation"],
      "cross_refs": []
    },
    {
      "id": "insight_019",
      "paper_id": "arxiv_2509.08646",
      "insight": "P-t-E trade-offs: Improved reasoning quality, cost efficiency, predictability, and prompt injection resistance vs upfront latency, high token consumption in planning, and wasted effort if early steps fail without re-planning",
      "tags": ["architecture", "trade-offs", "planning"],
      "cross_refs": ["arxiv_2601.03624"]
    },
    {
      "id": "insight_020",
      "paper_id": "arxiv_2505.07087",
      "insight": "Commitment & Reconsideration pattern is underexplored in LLM agents: ReAct implements observe-decide-act but lacks explicit commitment stage - introducing commitment may improve reasoning outcomes by enabling principled reconsidering of prior choices",
      "tags": ["cognitive-patterns", "reasoning", "gap-analysis"],
      "cross_refs": ["arxiv_2510.09244", "arxiv_2601.03624"]
    },
    {
      "id": "insight_021",
      "paper_id": "arxiv_2505.07087",
      "insight": "Knowledge Compilation pattern is strategically important: Caching LLM reasoning into reusable forms (ExpeL, Reflexion, Voyager) becomes increasingly valuable as reasoning model computational costs rise",
      "tags": ["cognitive-patterns", "efficiency", "caching"],
      "cross_refs": ["arxiv_2508.10146"]
    },
    {
      "id": "insight_022",
      "paper_id": "arxiv_2505.07087",
      "insight": "Step-wise Reflection is a novel LLM-specific pattern: Iterative self-evaluation during reasoning distinguishes itself from traditional metacognitive reflection in cognitive architectures - enables improved reliability without explicit commitment mechanisms",
      "tags": ["cognitive-patterns", "reflection", "novel-pattern"],
      "cross_refs": ["arxiv_2512.20845", "arxiv_2503.16024"]
    },
    {
      "id": "insight_023",
      "paper_id": "arxiv_2506.08837",
      "insight": "General-purpose agents cannot provide meaningful security guarantees - application-specific agents with constrained capabilities following secure design patterns are the only path to production-grade security",
      "tags": ["security", "architecture", "fundamental-principle"],
      "cross_refs": ["arxiv_2509.08646"]
    },
    {
      "id": "insight_024",
      "paper_id": "arxiv_2506.08837",
      "insight": "Six security patterns hierarchy: Action-Selector (max security, min flexibility) → Plan-Then-Execute (good balance) → Map-Reduce (parallel safe) → Dual LLM (privilege separation) → Code-Then-Execute (explicit reasoning) → Context-Minimization (simple implementation)",
      "tags": ["security", "patterns", "trade-offs"],
      "cross_refs": ["arxiv_2509.08646", "arxiv_2601.03624"]
    },
    {
      "id": "insight_025",
      "paper_id": "arxiv_2506.08837",
      "insight": "LLM Map-Reduce pattern: Isolated LLM instances process individual data chunks independently with outputs constrained to safe formats (booleans, categories). Prevents cross-document manipulation and limits blast radius to single items - ideal for batch classification, review aggregation, resume screening.",
      "tags": ["security", "patterns", "parallel-processing"],
      "cross_refs": []
    },
    {
      "id": "insight_026",
      "paper_id": "arxiv_2506.08837",
      "insight": "Context-Minimization pattern: Remove user prompts from context after driving initial actions but before processing tool results. Simple to implement, prevents user-injected instructions from manipulating responses to tool outputs.",
      "tags": ["security", "patterns", "context-management"],
      "cross_refs": ["arxiv_2509.08646"]
    }
  ],
  "visited_urls": [
    "https://export.arxiv.org/api/query?search_query=all:agentic+AI+LLM+agent+architecture",
    "https://export.arxiv.org/api/query?search_query=all:multi-agent+systems+LLM",
    "https://export.arxiv.org/api/query?search_query=all:ReAct+prompting+agent",
    "https://export.arxiv.org/api/query?search_query=all:tool+use+LLM+agent",
    "https://export.arxiv.org/api/query?search_query=all:agent+memory+RAG",
    "https://arxiv.org/abs/2601.03624",
    "https://arxiv.org/abs/2601.03328",
    "https://arxiv.org/abs/2510.09244",
    "https://arxiv.org/abs/2506.08837",
    "https://arxiv.org/abs/2508.10146",
    "https://arxiv.org/abs/2505.07087",
    "https://arxiv.org/abs/2404.11584",
    "https://arxiv.org/abs/2509.08646",
    "https://arxiv.org/abs/2511.03023",
    "https://arxiv.org/abs/2512.20845",
    "https://arxiv.org/abs/2503.16024",
    "https://arxiv.org/abs/2505.00875",
    "https://arxiv.org/abs/2511.02303",
    "https://arxiv.org/abs/2512.14474",
    "https://arxiv.org/abs/2502.05078",
    "https://arxiv.org/abs/2401.14295",
    "https://arxiv.org/html/2510.09244v1",
    "https://arxiv.org/pdf/2509.08646",
    "https://www.themoonlight.io/en/review/architecting-resilient-llm-agents-a-guide-to-secure-plan-then-execute-implementations",
    "https://community.sap.com/t5/security-and-compliance-blog-posts/plan-then-execute-an-architectural-pattern-for-responsible-agentic-ai/ba-p/14239753",
    "https://github.com/RichardHGL/CHI2025_Plan-then-Execute_LLMAgent",
    "https://arxiv.org/html/2505.07087v2",
    "https://link.springer.com/chapter/10.1007/978-3-032-00800-8_28",
    "https://github.com/SoarGroup/Soar",
    "https://github.com/soartech/jsoar",
    "https://github.com/ysymyth/awesome-language-agents",
    "https://arxiv.org/html/2506.08837v3",
    "https://pondevelopment.github.io/llm-prompt-injection-mitigation-patterns/",
    "https://github.com/tldrsec/prompt-injection-defenses",
    "https://simonwillison.net/2025/Jun/13/prompt-injection-design-patterns/"
  ],
  "blocked_sources": [],
  "statistics": {
    "total_discovered": 20,
    "total_analyzed": 7,
    "total_presented": 7,
    "total_rejected": 0,
    "total_insights_extracted": 26,
    "discovery_metrics": {
      "sources_tried": [
        "arXiv",
        "Google Scholar",
        "web"
      ],
      "sources_successful": [
        "arXiv",
        "Google Scholar",
        "web"
      ],
      "sources_blocked": [],
      "source_failure_reasons": {}
    },
    "analysis_metrics": {
      "avg_score": 22.43,
      "score_distribution": {
        "0-11": 0,
        "12-17": 0,
        "18-23": 5,
        "24-30": 2
      }
    }
  }
}
